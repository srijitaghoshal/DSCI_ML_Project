{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten, Permute, Reshape\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def import_data(stock, startDate):\n",
    "    data = yf.download(stock, start=startDate, interval='1d')\n",
    "    data.columns = data.columns.get_level_values(0)\n",
    "    data['EMA_50'] = ta.ema(data['Close'], length=50)\n",
    "    data['EMA_200'] = ta.ema(data['Close'], length=200)\n",
    "    data['SMA_50'] = ta.sma(data['Close'], length=50)\n",
    "    data['SMA_200'] = ta.sma(data['Close'], length=200)\n",
    "    data['RSI'] = ta.rsi(data['Close'], length=14)\n",
    "    data['Pct_Change_5D'] = data['Close'].pct_change(periods=5).shift(-5)  # Percent change over 5 days\n",
    "    data.dropna(inplace=True)  # Remove any rows with NaN values\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from keras.layers import LSTM, Dense, Dropout, AdditiveAttention, Permute, Reshape, Multiply, Flatten\n",
    "\n",
    "# data = import_data('SPY', '2016-01-01')\n",
    "# data.columns = data.columns.get_level_values(0)\n",
    "\n",
    "# # Rename the columns to their appropriate names\n",
    "# data.rename(columns={'Adj Close': 'Adj_Close', 'Close': 'Close', 'High': 'High', 'Low': 'Low',\n",
    "#                    'Open': 'Open', 'Volume': 'Volume'}, inplace=True)\n",
    "# data = data.dropna()\n",
    "# print(data)\n",
    "\n",
    "# # scalers = {}\n",
    "# # for column in ['Close', 'RSI', 'SMA_50', 'SMA_200', 'EMA_50', 'EMA_200', 'Volume']:\n",
    "# #     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# #     data[column] = scaler.fit_transform(data[column].values.reshape(-1, 1))\n",
    "# #     scalers[column] = scaler\n",
    "# step = 60\n",
    "# X, Y = [], []\n",
    "# # import all SPY tickers\n",
    "# sp500_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "# sp500_table = pd.read_html(sp500_url)\n",
    "# TICKERS = sp500_table[0]['Symbol'].tolist()\n",
    "# # import each ticker's data\n",
    "# for ticker in TICKERS:\n",
    "#     dataset = import_data(ticker, '2016-01-01')\n",
    "#     # scale all columns in data\n",
    "#     for column in ['RSI', 'SMA_50', 'SMA_200', 'EMA_50', 'EMA_200', 'Volume']:\n",
    "#         scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#         dataset[column] = scaler.fit_transform(dataset[column].values.reshape(-1, 1))\n",
    "#     for i in range(len(dataset) - step - 6):\n",
    "#         features = dataset[['Close', 'RSI', 'SMA_50', 'SMA_200', 'EMA_50', 'EMA_200', 'Volume']].iloc[i:(i + step)].values\n",
    "        \n",
    "#         current_price = dataset['Close'].iloc[i + step]\n",
    "#         future_price = dataset['Close'].iloc[i + step + 5]\n",
    "#         percent_change = ((future_price - current_price) / current_price) * 100\n",
    "        \n",
    "#         X.append(features)\n",
    "#         Y.append(percent_change)\n",
    "# X, Y = np.array(X), np.array(Y)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(50, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(50, return_sequences=True))\n",
    "# # attention = AdditiveAttention(name='attention_weight')\n",
    "\n",
    "# model.add(Permute((2, 1))) \n",
    "# model.add(Reshape((-1, X_train.shape[1])))\n",
    "# # attention_result = attention([model.output, model.output])\n",
    "# # multiply_layer = Multiply()([model.output, attention_result])\n",
    "\n",
    "# model.add(Permute((2, 1))) \n",
    "# model.add(Reshape((-1, 50)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# # model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2)\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=25, validation_split=0.2)\n",
    "\n",
    "# predictions = model.predict(X_test)\n",
    "# predictions = predictions.reshape(-1, 1)\n",
    "\n",
    "# print(predictions)\n",
    "\n",
    "# # Evaluate the model\n",
    "# mae = mean_absolute_error(y_test, predictions)\n",
    "# rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "# print(\"Mean Absolute Error: \", mae)\n",
    "# print(\"Root Mean Square Error: \", rmse)  \n",
    "\n",
    "# plt.plot(y_test, label='Original Data')\n",
    "# plt.plot(np.arange(len(y_train) + step, len(y_train) + len(predictions) + step), predictions, label='Predicted Data', color='red')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('Stock Price')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from backtesting import Strategy, Backtest\n",
    "\n",
    "# def get_parameters(df):\n",
    "#     # Define the signal function that will be used in the strategy\n",
    "#     def SIGNAL():\n",
    "#         return df['pc_change']\n",
    "    \n",
    "#     class MA_Crossover_RSI_Strategy(Strategy):\n",
    "#         mysize = 1  # Trade size (100% of available cash)\n",
    "#         trade_age = 0\n",
    "#         threshold = 1\n",
    "\n",
    "#         def init(self):\n",
    "#             # Initialize the signal\n",
    "#             self.signal1 = self.I(SIGNAL)\n",
    "\n",
    "#         def next(self):\n",
    "#             # If no open position and a signal occurs, enter a buy order\n",
    "#             if abs(self.signal1) > self.threshold and not self.position:\n",
    "#                 if self.signal1 > 0:\n",
    "#                     self.buy(size=self.mysize)\n",
    "#                 else:\n",
    "#                     self.sell(size=self.mysize)\n",
    "#                 # print(f\"BUY at {entry_price}, Stop Loss at {stop_loss}\")\n",
    "\n",
    "#             # If signal is 5 days old, close position\n",
    "#             if self.position:\n",
    "#                 if self.trade_age >= 5:\n",
    "#                     self.position.close()\n",
    "#                     self.trade_age = 0\n",
    "#                 else:\n",
    "#                     self.trade_age += 1\n",
    "\n",
    "#     # Run the backtest\n",
    "#     bt = Backtest(df, MA_Crossover_RSI_Strategy, cash=10000, margin=1/30, commission=0.01)\n",
    "#     results = bt.run()\n",
    "\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lstm_data(data, feature_columns, target_column, time_steps=60):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(time_steps, len(data) - 5):  # Ensure we have future data for Y\n",
    "        X.append(data[feature_columns].iloc[i - time_steps:i].values)\n",
    "        Y.append(data[target_column].iloc[i])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MMM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping MMM due to an error: slice indices must be integers or None or have an __index__ method\n",
      "Processing AOS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping AOS due to an error: slice indices must be integers or None or have an __index__ method\n",
      "Processing ABT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping ABT due to an error: slice indices must be integers or None or have an __index__ method\n",
      "Processing ABBV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping ABBV due to an error: slice indices must be integers or None or have an __index__ method\n",
      "Processing ACN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping ACN due to an error: slice indices must be integers or None or have an __index__ method\n",
      "Processing ADBE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping ADBE due to an error: slice indices must be integers or None or have an __index__ method\n",
      "Processing AMD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping AMD due to an error: slice indices must be integers or None or have an __index__ method\n",
      "Processing AES...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping AES due to an error: slice indices must be integers or None or have an __index__ method\n",
      "Processing AFL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping AFL due to an error: slice indices must be integers or None or have an __index__ method\n",
      "Processing A...\n",
      "Skipping A due to an error: slice indices must be integers or None or have an __index__ method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sp500_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "sp500_table = pd.read_html(sp500_url)\n",
    "TICKERS = sp500_table[0]['Symbol'].tolist()\n",
    "\n",
    "# Select a subset for faster testing\n",
    "TICKERS = TICKERS[:10]  # Adjust as needed\n",
    "\n",
    "# Prepare data for training\n",
    "feature_columns = ['Close', 'EMA_50', 'EMA_200', 'SMA_50', 'SMA_200', 'RSI']\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "time_steps = 60  # Number of time steps for LSTM\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    # print(f\"Processing {ticker}...\")\n",
    "    try:\n",
    "        data = import_data(ticker, startDate='2023-01-01')\n",
    "        data[feature_columns] = scaler.fit_transform(data[feature_columns])\n",
    "        X, Y = prepare_lstm_data(data, feature_columns, 'Pct_Change_5D', time_steps)\n",
    "        if len(X) > 0 and len(Y) > 0:\n",
    "            length = len(X)\n",
    "            index = 0.8*length\n",
    "            X_train.extend(X[:index])\n",
    "            Y_train.extend(Y[:index])\n",
    "            X_test.extend(X[index:])\n",
    "            Y_test.extend(Y[index:])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {ticker} due to an error: {e}\")\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39madd(LSTM(\u001b[38;5;241m50\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])))\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.2\u001b[39m))\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(LSTM(\u001b[38;5;241m50\u001b[39m))\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(model, tickers, start_date, feature_columns, time_steps=60):\n",
    "    capital = 10000  # Starting capital\n",
    "    equity_curve = [capital]\n",
    "    current_capital = capital\n",
    "\n",
    "    # Create a combined dataframe for all tickers with predicted values\n",
    "    combined_data = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        print(f\"Backtesting {ticker}...\")\n",
    "        try:\n",
    "            data = import_data(ticker, startDate=start_date)\n",
    "            data[feature_columns] = scaler.transform(data[feature_columns])\n",
    "            X_test, _ = prepare_lstm_data(data, feature_columns, 'Pct_Change_5D', time_steps)\n",
    "\n",
    "            # Predict and add to combined data\n",
    "            data['Predicted'] = np.nan\n",
    "            for i in range(time_steps, len(data) - 5):\n",
    "                pred = model.predict(X_test[i - time_steps].reshape(1, time_steps, -1), verbose=0)\n",
    "                data.loc[data.index[i], 'Predicted'] = pred\n",
    "            combined_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {ticker} due to an error: {e}\")\n",
    "\n",
    "    print(data.index[-1])\n",
    "    for i in range(len(combined_data)):\n",
    "        combined_data[i].index = combined_data[i].index.tz_localize(None)\n",
    "    # Simulate backtesting over the given period\n",
    "    for date in pd.date_range(start=start_date, end=data.index[-1]):\n",
    "        best_stock = None\n",
    "        max_pred = -np.inf\n",
    "\n",
    "        # Find the stock with the highest predicted percent change for the given day\n",
    "        for data in combined_data:\n",
    "            if date in data.index and not pd.isna(data.loc[date, 'Predicted']):\n",
    "                if data.loc[date, 'Predicted'] > max_pred:\n",
    "                    max_pred = data.loc[date, 'Predicted']\n",
    "                    best_stock = data\n",
    "\n",
    "        # \"Buy\" the stock with the highest predicted change\n",
    "        if best_stock is not None:\n",
    "            buy_price = best_stock.loc[date, 'Close']\n",
    "            future_date = date + pd.Timedelta(days=5)\n",
    "            if future_date in best_stock.index:\n",
    "                sell_price = best_stock.loc[future_date, 'Close']\n",
    "                profit = (sell_price - buy_price) / buy_price * current_capital\n",
    "                current_capital += profit\n",
    "                equity_curve.append(current_capital)\n",
    "\n",
    "    return equity_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# start_date = '2022-06-01'\n",
    "# equity_curve = backtest(model, TICKERS, start_date, feature_columns, time_steps)\n",
    "\n",
    "# # Plot the equity curve\n",
    "# plt.plot(equity_curve)\n",
    "# plt.title('Equity Curve')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('Equity ($)')\n",
    "# plt.show()\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "roc_auc = roc_auc_score(Y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
